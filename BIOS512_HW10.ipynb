{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18765b9e-dd17-46f1-a838-679674ed8768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'httr' is in use and will not be installed\"\n",
      "Installing package into 'C:/Users/keert/AppData/Local/R/win-library/4.4'\n",
      "(as 'lib' is unspecified)\n",
      "\n",
      "also installing the dependency 'SnowballC'\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'SnowballC' successfully unpacked and MD5 sums checked\n",
      "package 'tokenizers' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\keert\\AppData\\Local\\Temp\\RtmpKg3KNH\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tokenizers' was built under R version 4.4.3\"\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"httr\")\n",
    "install.packages(\"tokenizers\")\n",
    "library(httr)\n",
    "library(tokenizers)\n",
    "\n",
    "tokenize_text <- function(text) {\n",
    "    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf565f0-081a-4c57-b559-c0b553aa492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_from <- function(ngram, sep = \"\\x1f\") {\n",
    "    paste(ngram, collapse=sep)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8de6170-1045-4c8c-a7e0-c6198cb9ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
    "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
    "    tbl <- new.env(parent = emptyenv())\n",
    "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
    "        ngram <- tokens[i:(i + n - 2L)]\n",
    "        next_word <- tokens[i + n - 1L]\n",
    "        key <- paste(ngram, collapse = sep)\n",
    "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "        if (next_word %in% names(counts)) {\n",
    "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
    "        } else {\n",
    "            counts[[next_word]] <- 1L\n",
    "        }\n",
    "        tbl[[key]] <- counts\n",
    "    }\n",
    "    tbl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd11b6a1-fe0e-4df2-8ff9-775860d7a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_text <- function(text, n) {\n",
    "    tokens <- tokenize_text(text)\n",
    "    build_ngram_table(tokens, n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe6b58a-1752-4651-9d82-4e9484cf13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_url <- function(url, n) {\n",
    "    res <- httr::GET(url)\n",
    "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
    "    digest_text(txt,n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28241c70-4719-44ed-a1d2-278ae00a54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_start <- function(tbl, sep = \"\\x1f\") {\n",
    "    keys <- ls(envir = tbl, all.names=TRUE)\n",
    "    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
    "    picked <- sample(keys, 1)\n",
    "    strsplit(picked, sep, fixed=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "530dad20-c1c4-49b8-967f-0fe91bc5183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
    "    key <- paste(ngram, collapse = sep)\n",
    "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "    if (length(counts) == 0) return(NA_character_)\n",
    "    sample(names(counts), size=1, prob=as.numeric(counts))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e42ec6ef-867a-47ee-b783-3d254efeb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
    "    force(tbl); n <- as.integer(n); force(sep)\n",
    "    function(start_words = NULL, length = 10L) {\n",
    "        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
    "            start_words <- random_start(tbl, sep=sep)\n",
    "        }\n",
    "        word_sequence <- start_words\n",
    "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
    "            ngram <- tail(word_sequence, n - 1L)\n",
    "            next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
    "            if (is.na(next_word)) break\n",
    "            word_sequence <- c(word_sequence, next_word)\n",
    "        }\n",
    "        paste(word_sequence, collapse= \" \")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db963b0f-c7f8-459e-82a8-c132e105d20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'the king has forbidden me to marry another husband am not i shall ride upon'"
      ],
      "text/latex": [
       "'the king has forbidden me to marry another husband am not i shall ride upon'"
      ],
      "text/markdown": [
       "'the king has forbidden me to marry another husband am not i shall ride upon'"
      ],
      "text/plain": [
       "[1] \"the king has forbidden me to marry another husband am not i shall ride upon\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a) i) Using it (n=3) start word \"the king\"\n",
    "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "\n",
    "set.seed(2025)\n",
    "tbl3 <- digest_url(url, n = 3)\n",
    "gen3 <- make_ngram_generator(tbl3, n = 3)\n",
    "\n",
    "# Generate text starting with \"the king\"\n",
    "gen3(start_words = c(\"the\", \"king\"), length = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d9a877-d2af-47fb-aa50-5e9aee7af279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'spread the jam over it spread its wings and crying here comes our hobblety jib'"
      ],
      "text/latex": [
       "'spread the jam over it spread its wings and crying here comes our hobblety jib'"
      ],
      "text/markdown": [
       "'spread the jam over it spread its wings and crying here comes our hobblety jib'"
      ],
      "text/plain": [
       "[1] \"spread the jam over it spread its wings and crying here comes our hobblety jib\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a) ii) \n",
    "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "\n",
    "set.seed(2025)\n",
    "tbl3 <- digest_url(url, n = 3)\n",
    "gen3 <- make_ngram_generator(tbl3, n = 3)\n",
    "\n",
    "# Generate random start\n",
    "gen3(length = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faafcbd9-b630-4539-bbfd-a88ed10fe256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'the king he added to the entire exclusion of the swords were made prisoners the'"
      ],
      "text/latex": [
       "'the king he added to the entire exclusion of the swords were made prisoners the'"
      ],
      "text/markdown": [
       "'the king he added to the entire exclusion of the swords were made prisoners the'"
      ],
      "text/plain": [
       "[1] \"the king he added to the entire exclusion of the swords were made prisoners the\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# b) i) Using it (n=3) start word \"the king\"\n",
    "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "\n",
    "set.seed(2025)\n",
    "tbl3 <- digest_url(url, n = 3)\n",
    "gen3 <- make_ngram_generator(tbl3, n = 3)\n",
    "\n",
    "# Generate text starting with \"the king\"\n",
    "gen3(start_words = c(\"the\", \"king\"), length = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21b942bb-2257-4cdb-8b14-cc126525ecf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'laces of silk d milōn le cuireu͂r xxxviij pa͂r alec͂t co͂r p\\'̄c pa͂r iiij d'"
      ],
      "text/latex": [
       "'laces of silk d milōn le cuireu͂r xxxviij pa͂r alec͂t co͂r p\\textbackslash{}'̄c pa͂r iiij d'"
      ],
      "text/markdown": [
       "'laces of silk d milōn le cuireu͂r xxxviij pa͂r alec͂t co͂r p\\'̄c pa͂r iiij d'"
      ],
      "text/plain": [
       "[1] \"laces of silk d milōn le cuireu͂r xxxviij pa͂r alec͂t co͂r p'̄c pa͂r iiij d\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# b) ii) \n",
    "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "\n",
    "set.seed(2025)\n",
    "tbl3 <- digest_url(url, n = 3)\n",
    "gen3 <- make_ngram_generator(tbl3, n = 3)\n",
    "\n",
    "# Generate random start\n",
    "gen3(length = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720485cf-bb9c-4793-8036-4c77d312dfb1",
   "metadata": {},
   "source": [
    "The content generated from each source is different because the vocabulary and the ngrams are different between the sources. Because sampling is probabalistic, how often a word appears also differs and the starting word changes based on whether you set one or if it is random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? \n",
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2d045-6443-4fb2-b4ec-84c57bef98ae",
   "metadata": {},
   "source": [
    "a) A language learning model is a type of machine learning model that predicts the probability of a sequence of words to understand and generate human language\n",
    "\n",
    "b) You can run a language model locally by sending HTTP API requests through a program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | a program that interprets the command. The shell parses the command and launches the mkdir process with \"project\" as an argument |\n",
    "| **Terminal emulator** | hosts the shell. shows the text you type and the output you get so in this case the \"mkdir project' |\n",
    "| **Process** | something running on your computer. The shell creates a new process that runs the mkdir program. |\n",
    "| **Signal** | something that you can can send to processes to tell them to do something. This example doesn't normally use a signal but you can send a signal to interrupt it |\n",
    "| **Standard input** | something that each process has - A text stream that a process can read from |\n",
    "| **Standard output** | something that each process has - A text stream that a process writes normal output to |\n",
    "| **Command line argument** | the things that you can pass to a process when you start it - the word \"project\" is the command-line argument telling mkdir which directory to create|\n",
    "| **The environment** | all the stuff a process can see when its running - in this case a set of variables passed to the mkdir process by the shell |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?\n",
    "#### b) Explain what this command is doing, part by part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c680d4-1f9d-4807-8ae7-8b941c6e3ef3",
   "metadata": {},
   "source": [
    "a) the programs are:\n",
    "find – searches for files and directories \\\n",
    "xargs – builds command lines from input \\\n",
    "grep – searches text inside files \n",
    "\n",
    "b) This command is finding searches starting in the current directory (.) \\\n",
    "-iname \"*.R\" finds files whose names end in .R. \\\n",
    "Output is a list of .R file paths, one per line. \\\n",
    "the pipe takes the output of find and uses it as the input to xargs \\\n",
    "xargs takes all the filenames from find and appends them to the end of a grep command \\\n",
    "grep read_csv searches each file for lines that contain the text read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`.\n",
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
    "#### c) How do you log in to the RStudio server?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf474563-0240-496d-9344-6690654f5e21",
   "metadata": {},
   "source": [
    "a) Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    "    (amd64)\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    " https://hub.docker.com/\n",
    "\n",
    "For more examples and ideas, visit:\n",
    " https://docs.docker.com/get-started/\n",
    "\n",
    "\n",
    "b) docker run -d -p 8787:8787 -e PASSWORD=docker! --name rstudio rocker/rstudio      4dc039b79aa0aae501bc831a5e519ea58f1474257ecef9b24922b3b8e3267771\n",
    "\n",
    "I logged into the Rstudio using my server and password"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
